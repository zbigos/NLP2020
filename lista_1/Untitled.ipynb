{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LISTA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBAL SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import statistics\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "from sys import getsizeof\n",
    "import sys\n",
    "import copy\n",
    "import nltk\n",
    "import collections\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZADANIE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16a575d744754b5988688cdc70c3a470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59134224.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "read 3591116, longest one is 125\n"
     ]
    }
   ],
   "source": [
    "def Succ1Grams():\n",
    "    data = set()\n",
    "    \n",
    "    #num_lines = sum(1 for line in open('poleval_2grams.txt'))\n",
    "    num_lines = 59134224\n",
    "    lines_read = 0\n",
    "    with open(\"poleval_2grams.txt\", \"r\") as f:\n",
    "        with tqdm(total=num_lines) as pbar:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                if lines_read > 10000:\n",
    "                    pbar.update(lines_read)\n",
    "                    lines_read = 0\n",
    "                    pbar.set_description(f\"memory used {sys.getsizeof(data)/1024/1024} MB\")\n",
    "                lines_read += 1\n",
    "                wc, wl, wp = line.replace(\"\\n\", \"\").split(\" \")\n",
    "                data.add(wl)\n",
    "                data.add(wp)\n",
    "\n",
    "                #if len(t) < 50:\n",
    "                #    data.append(t)\n",
    "                line = f.readline()\n",
    "                if len(data) > 10000000:\n",
    "                    break\n",
    "    return data\n",
    "\n",
    "singletons = Succ1Grams()\n",
    "maxlen = max(len(s) for s in singletons)\n",
    "print(f\"read {len(singletons)}, longest one is {maxlen}\")\n",
    "maxlen = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OwnMatch(w):\n",
    "    graph = [[] for _ in w]\n",
    "    for slit in range(len(w)):\n",
    "        for forward_succ in range(5):\n",
    "            taken = w[slit:slit+forward_succ+1]\n",
    "            if len(taken) == forward_succ+1:\n",
    "                if taken in singletons:\n",
    "                    graph[slit].append(slit + forward_succ + 1)\n",
    "\n",
    "    #print(f\"neighbor matrix\")\n",
    "    #display(graph)\n",
    "\n",
    "    dp = [(0, None) for _ in range(len(w)+1)]\n",
    "    for i in range(len(w)-1):\n",
    "        for jt in graph[i]:\n",
    "            if dp[jt][0] < (dp[i][0] + (i-jt)**2):\n",
    "                dp[jt] = (dp[i][0] + (i-jt)**2, i)\n",
    "\n",
    "    #display(dp)\n",
    "\n",
    "    baked = []\n",
    "    ls = dp[-1][1]\n",
    "    fs = len(w)\n",
    "    while ls != None:\n",
    "        baked.append(w[ls:fs])\n",
    "        fs = ls\n",
    "        ls = dp[ls][1]\n",
    "        \n",
    "    baked.reverse()\n",
    "    \n",
    "    return baked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaxMatch(w, verbose = False):\n",
    "    wp = w\n",
    "    tokenized = []\n",
    "    succ = 1\n",
    "    best = (0, \"reeee\")\n",
    "    \n",
    "    while len(w) > 0:\n",
    "        try_ = w[:succ]\n",
    "        if try_ in singletons:\n",
    "            if verbose:\n",
    "                print(f\"found candidate {try_}\")\n",
    "            best = (succ, try_) \n",
    "\n",
    "        succ += 1\n",
    "        \n",
    "        if succ > maxlen or try_ == w:\n",
    "            if best[0] == 0:\n",
    "                raise Exception(f\"could not match {w[:succ]} in {wp}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"longest match was {best[1]}\")\n",
    "                tokenized.append(best[1])\n",
    "                if verbose:\n",
    "                    print(f\"transforming {w} -> {w[best[0]:]}\")\n",
    "                w = w[best[0]:]\n",
    "                succ = 1\n",
    "                best = (0, \"reeee\")\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation stolen from https://blog.paperspace.com/implementing-levenshtein-distance-word-autocomplete-autocorrect/\n",
    "# since jupyter considered that importing\n",
    "# python-levenstein is on the same level as breaking the geneva\n",
    "# convention\n",
    "\n",
    "def levenshteinDistanceDP(token1, token2):\n",
    "    distances = np.zeros((len(token1) + 1, len(token2) + 1))\n",
    "\n",
    "    for t1 in range(len(token1) + 1):\n",
    "        distances[t1][0] = t1\n",
    "\n",
    "    for t2 in range(len(token2) + 1):\n",
    "        distances[0][t2] = t2\n",
    "        \n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    \n",
    "    for t1 in range(1, len(token1) + 1):\n",
    "        for t2 in range(1, len(token2) + 1):\n",
    "            if (token1[t1-1] == token2[t2-1]):\n",
    "                distances[t1][t2] = distances[t1 - 1][t2 - 1]\n",
    "            else:\n",
    "                a = distances[t1][t2 - 1]\n",
    "                b = distances[t1 - 1][t2]\n",
    "                c = distances[t1 - 1][t2 - 1]\n",
    "                \n",
    "                if (a <= b and a <= c):\n",
    "                    distances[t1][t2] = a + 1\n",
    "                elif (b <= a and b <= c):\n",
    "                    distances[t1][t2] = b + 1\n",
    "                else:\n",
    "                    distances[t1][t2] = c + 1\n",
    "\n",
    "    return distances[len(token1)][len(token2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_test(compare_string):\n",
    "    digested = compare_string.replace(\" \", \"\")\n",
    "    p1 = \" \".join(MaxMatch(digested))\n",
    "    p2 = \" \".join(OwnMatch(digested))\n",
    "    s1 = levenshteinDistanceDP(compare_string, p1)\n",
    "    s2 = levenshteinDistanceDP(compare_string, p2)\n",
    "    #print(compare_string)\n",
    "    #print(f\"MaxMatch returned {p1}, score {s1}\")\n",
    "    #print(f\"OwnCrap returned {p2}, score {s2}\")\n",
    "    return (s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345f6de18ba0456e9f08bbc4d758c8bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MaxMatch:\n",
      "Mean: 5.6\n",
      "Stdev: 3.547299442298794\n",
      "max: 12.0\n",
      "min: 0.0\n",
      "MyCrap:\n",
      "Mean: 17.8\n",
      "Stdev: 16.91646141090585\n",
      "max: 48.0\n",
      "min: 3.0\n"
     ]
    }
   ],
   "source": [
    "poem = '''Jedzie Wojtuś popod lasem, skrajem dąbrowy,\n",
    "Wiezie se do domu laser, laser gazowy.\n",
    "Pytali się go kolesie, po co to nabył?\n",
    "- A bo właśnie stał w GS-ie, więc kupiłem go Teresie.\n",
    "Dyć coś zawsze przywieźć chce się dla swej baby!\n",
    "Jedzie Wojtuś popod lasem, po twardym dukcie.\n",
    "Wiezie se do domu laser, czyta instrukcję.\n",
    "A instrukcja jest ciekawa: Włączyć do prądu,\n",
    "To ten laser wszystko skrawa, bez różnicy, stal czy trawa\n",
    "I w ogóle jest zabawa prawie bez swądu.\n",
    "Jedzie Wojtuś popod lasem, woła: Wio, wiśta!\n",
    "Wiezie se do domu laser, tak se rozmyśla:\n",
    "Jak w tym dojdę do biegłości, będzie wygodnie,\n",
    "Jest tu paru wrednych gości, przyceluję se w skrytości\n",
    "I padalcom z odległości podpalę spodnie!\n",
    "Jedzie Wojtuś popod lasem, rad, że o rany\n",
    "Wiezie se do domu laser, układa plany:\n",
    "Niech spróbuje na rowerze jeździć Kaczmarski,\n",
    "Zaraz w dętkę mu przymierzę, i kartofle się obierze,\n",
    "I wywierci dziury w serze, by był śwajcarski!\n",
    "Jedzie Wojtuś popod lasem, skręcił przy POM-ie.\n",
    "Wiezie se do domu laser schowany w słomie.\n",
    "Na podwórku cielę bryka, kaczki na stawie...\n",
    "Wdziera, wdziera się technika coraz częściej w dom rolnika,\n",
    "Jeszcze to nie Ameryka.... Ale już prawie!!! '''\n",
    "\n",
    "tMM, tMC = [], []\n",
    "for l in tqdm(poem.split(\"\\n\")):\n",
    "    retMM, retMC = perform_test(l.lower().replace(\",\", \"\"))\n",
    "    tMM.append(retMM)\n",
    "    tMC.append(retMC)\n",
    "    \n",
    "print(\"MaxMatch:\")\n",
    "print(f\"Mean: {statistics.mean(tMM)}\")\n",
    "print(f\"Stdev: {statistics.stdev(tMM)}\")\n",
    "print(f\"max: {max(tMM)}\")\n",
    "print(f\"min: {min(tMM)}\")\n",
    "\n",
    "print(\"MyCrap:\")\n",
    "print(f\"Mean: {statistics.mean(tMC)}\")\n",
    "print(f\"Stdev: {statistics.stdev(tMC)}\")\n",
    "print(f\"max: {max(tMC)}\")\n",
    "print(f\"min: {min(tMC)}\")\n",
    "\n",
    "\n",
    "#MaxMatch:\n",
    "#Mean: 5.96\n",
    "#Stdev: 4.6141087980237305\n",
    "#max: 17.0\n",
    "#min: 0.0\n",
    "#MyCrap:\n",
    "#Mean: 13.68\n",
    "#Stdev: 12.294036494712927\n",
    "#max: 48.0\n",
    "#min: 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZADANIE 2 i 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5eda69a41247c5b5bb9c2de18f8dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=59134224.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.calculate_bigrams.<locals>.<lambda>()>,\n",
       "            {'.': 1.2985921145254358e-06,\n",
       "             ',': 1.8757441654256295e-06,\n",
       "             '-': 1.923840169667312e-07,\n",
       "             'w': 5.290560466585109e-07,\n",
       "             'z': 7.695360678669248e-07,\n",
       "             'i': 4.80960042416828e-07,\n",
       "             'blada': 9.61920084833656e-07,\n",
       "             'a': 1.923840169667312e-07,\n",
       "             'latynoski': 2.40480021208414e-07,\n",
       "             'nie': 3.3667202969177965e-07,\n",
       "             'zbita': 4.3286403817514525e-07,\n",
       "             'dupy': 1.923840169667312e-07,\n",
       "             'boli': 1.923840169667312e-07,\n",
       "             'sex': 3.3667202969177965e-07,\n",
       "             'się': 1.4428801272504842e-07,\n",
       "             'to': 1.4428801272504842e-07,\n",
       "             'ze': 2.8857602545009683e-07,\n",
       "             'weza': 1.4428801272504842e-07,\n",
       "             'jest': 2.8857602545009683e-07,\n",
       "             '...': 3.3667202969177965e-07,\n",
       "             'na': 2.40480021208414e-07,\n",
       "             'albo': 1.4428801272504842e-07,\n",
       "             'fetysz': 1.923840169667312e-07})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_bigrams():\n",
    "    ins = collections.defaultdict(lambda: 0)\n",
    "    bigrams = collections.defaultdict(lambda: copy.deepcopy(ins))\n",
    "    num_lines = 59134224\n",
    "    lines_read = 0\n",
    "    maxim = 0\n",
    "    with open(\"poleval_2grams.txt\", \"r\") as f:\n",
    "        with tqdm(total=num_lines) as pbar:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                if lines_read > 10000:\n",
    "                    pbar.update(lines_read)\n",
    "                    lines_read = 0\n",
    "                    pbar.set_description(f\"memory used {sys.getsizeof(bigrams)/1024/1024} MB\")\n",
    "                lines_read += 1\n",
    "                wc, wl, wp = line.replace(\"\\n\", \"\").split(\" \")\n",
    "                if int(wc) > 2:\n",
    "                    bigrams[wl][wp] += int(wc)\n",
    "                    maxim = max(bigrams[wl][wp], maxim)\n",
    "\n",
    "                line = f.readline()\n",
    "                if len(bigrams) > 10000000:\n",
    "                    break\n",
    "    \n",
    "    for w1 in bigrams.keys():\n",
    "        for w2 in bigrams[w1].keys():\n",
    "            bigrams[w1][w2] = float(bigrams[w1][w2])/float(maxim)\n",
    "    return bigrams\n",
    "            \n",
    "bigrams = calculate_bigrams()\n",
    "bigrams['dupa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def generate_story(max_len, starting, distribution):\n",
    "    if max_len == 0:\n",
    "        max_len = 1000000\n",
    "    if starting == None:\n",
    "        starting = \"<BOS>\"\n",
    "        \n",
    "    while(max_len > 0):\n",
    "        print(starting, end = ' ')\n",
    "        max_len -= 1\n",
    "        candidates = bigrams[starting]\n",
    "        \n",
    "        if distribution == \"random\":\n",
    "            candidates = [i[0] for i in candidates.items()]\n",
    "            if len(candidates) == 0:\n",
    "                return\n",
    "            starting = random.choice(candidates) \n",
    "            \n",
    "        if distribution == \"weight\":\n",
    "            if len([i[0] for i in candidates.items()]) == 0:\n",
    "                return\n",
    "            \n",
    "            all_ents = sum([i[1] for i in candidates.items()])\n",
    "            chosen = random.randint(0, all_ents)\n",
    "            for cit in candidates.items():\n",
    "                chosen -= cit[1]\n",
    "                if chosen <= 0:\n",
    "                    starting = cit[0]\n",
    "                    break\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papież jest głosowanie , nakazów zapłaty za wykonywanie tych słów ) . <EOS> \n",
      "=======\n",
      "papież jan piotr jest to pielęgniarki i środowiskowe , a następnie o zmianie niektórych innych źródeł , czyli nie pojawiła się w związku z dnia 31 marca 2004 r. <EOS> \n",
      "=======\n",
      "papież w dramacie telewizyjnym , woda nie tylko w klimacie tropikalnym i przekształcić się na pomocy na liście : świnoujście sa w polsce od przedmiotów : dlaczego otrzymał nagrodę , jak najszybsze ich wpływem wilgoci i onkologii i czystości , który w którym jest własnością . <EOS> \n",
      "=======\n",
      "papież bonifacy ix . <EOS> \n",
      "=======\n",
      "papież urban , sprzeciwiał się największą , stefana żeromskiego ) lub dodatków odzieżowych i najważniejszych festiwalach : nie powinno być przez żydów z liczbą emerytów i społecznych , maria nuova , natomiast dynamika w czwórce podwójnej na niej dwa dni otwarte w 103 . <EOS> \n",
      "=======\n",
      "papież klemens v w poprzedniej części przed ewentualnymi zmianami , zdobył drużynowe mistrzostwo świata , tylko i zatrudnienia , wszystkie inne środowiska i 2007 ) , powołano go za zgłoszonych w procesie , niepublikowane . <EOS> \n",
      "=======\n",
      "papież i lubiane przez radę adwokacką . <EOS> \n",
      "=======\n",
      "papież benedykt xvi wieku , wynająć . <EOS> \n",
      "=======\n",
      "papież pius vii kadencji . <EOS> \n",
      "=======\n",
      "papież benedykt xvi i w ust . <EOS> \n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    generate_story(0, \"papież\", \"weight\")\n",
    "    print(\"\\n=======\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZADANIE 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sufix(suflen):\n",
    "    ins = collections.defaultdict(lambda: 0)\n",
    "    sufgrams = collections.defaultdict(lambda: copy.deepcopy(ins))\n",
    "    procd = 0\n",
    "    pbar = tqdm(total=len(bigrams.keys()))\n",
    "    \n",
    "    for w1 in bigrams.keys():\n",
    "        procd += 1\n",
    "\n",
    "        if procd > 1000:\n",
    "            procd = 0\n",
    "            pbar.update(1000)\n",
    "            pbar.set_description(f\"memory used {str(sys.getsizeof(sufgrams)/1024/1024)[:5]} MB\")\n",
    "\n",
    "        if len(w1) > suflen:\n",
    "            pref_sufix = str(w1)[-suflen:]\n",
    "            for w2 in bigrams[w1].keys():\n",
    "                if len(str(w2)) > suflen:\n",
    "                    suf_sufix = str(w2)[-suflen:]\n",
    "                    sufgrams[pref_sufix][suf_sufix] += bigrams[w1][w2]\n",
    "                    \n",
    "    # normalize ...\n",
    "    biggest = 0\n",
    "    for w1 in sufgrams.keys():\n",
    "        for w2 in sufgrams[w1].keys():\n",
    "            biggest = max(biggest, sufgrams[w1][w2])\n",
    "    print(f\"maximum score was {biggest}\")\n",
    "    for w1 in sufgrams.keys():\n",
    "        for w2 in sufgrams[w1].keys():\n",
    "            sufgrams[w1][w2] = float(sufgrams[w1][w2])/float(biggest)\n",
    "    \n",
    "    pbar.close()\n",
    "    return sufgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c2da1e7c9724875b88953019c48f943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=648483.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 0.30078178130967553\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18cd9e888009479bb4646e1b8ea1016c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=648483.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 0.09357313295628578\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97dcc0b63c6a4e65bbddb0625b1e8a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=648483.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 0.04880373694410105\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc28740692bb4a8fadb9739b03f910fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=648483.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 0.012760014213331365\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f145e3ee9164a25a97a70b5f4add4d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=648483.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 0.00618716617765856\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bigram_suflist = [calculate_sufix(i) for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a4ba371d4742149043382b4ea71f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=179473348.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "normalize by 762373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "            {',': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'tak': 3.9350816463856934e-06,\n",
       "                          'bo': 3.9350816463856934e-06,\n",
       "                          'nie': 3.9350816463856934e-06}),\n",
       "             'przebieralnia': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'na': 2.6233877642571285e-06}),\n",
       "             'orgasms': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'porno': 2.6233877642571285e-06}),\n",
       "             'i': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'kamieni': 3.9350816463856934e-06}),\n",
       "             '...': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'<EOS>': 7.870163292771387e-06}),\n",
       "             'w': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'pończochach': 2.6233877642571285e-06}),\n",
       "             'dupy': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'w': 2.6233877642571285e-06}),\n",
       "             'www': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'sex': 2.6233877642571285e-06}),\n",
       "             'a': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'nie': 2.6233877642571285e-06}),\n",
       "             'z': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'tyłu': 2.6233877642571285e-06,\n",
       "                          'tego': 3.9350816463856934e-06}),\n",
       "             'jest': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'.': 2.6233877642571285e-06}),\n",
       "             'sekretarki': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'nago': 2.6233877642571285e-06}),\n",
       "             'sex': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'strony': 2.6233877642571285e-06,\n",
       "                          'w': 2.6233877642571285e-06,\n",
       "                          'filmy': 2.6233877642571285e-06}),\n",
       "             'dzikie': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'azjatki': 2.6233877642571285e-06}),\n",
       "             'wolowa': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {',': 2.6233877642571285e-06}),\n",
       "             'mamy': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'25': 2.6233877642571285e-06}),\n",
       "             'czterdziestolatki': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'vex': 2.6233877642571285e-06}),\n",
       "             '!': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'<EOS>': 2.6233877642571285e-06}),\n",
       "             'weza': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'i': 2.6233877642571285e-06}),\n",
       "             'fetysz': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'stóp': 5.246775528514257e-06}),\n",
       "             'youtube': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'porno': 2.6233877642571285e-06}),\n",
       "             'amatorski': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'sex': 2.6233877642571285e-06}),\n",
       "             'to': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'nie': 2.6233877642571285e-06}),\n",
       "             '.': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'<EOS>': 3.541573481747124e-05}),\n",
       "             'blada': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'.': 1.180524493915708e-05,\n",
       "                          ',': 3.9350816463856934e-06}),\n",
       "             'zbita': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {',': 2.6233877642571285e-06,\n",
       "                          '.': 3.9350816463856934e-06}),\n",
       "             'nie': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'jest': 2.6233877642571285e-06}),\n",
       "             'porno': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'w': 2.6233877642571285e-06}),\n",
       "             'po': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'sraniu': 2.6233877642571285e-06}),\n",
       "             'starsze': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'murzynki': 2.6233877642571285e-06}),\n",
       "             'latynoski': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'galeria': 2.6233877642571285e-06}),\n",
       "             'puszyste': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'panie': 2.6233877642571285e-06}),\n",
       "             'ze': defaultdict(<function __main__.succ_3grams.<locals>.<lambda>()>,\n",
       "                         {'mnie': 2.6233877642571285e-06})})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def succ_3grams():\n",
    "    ins = collections.defaultdict(lambda: 0)\n",
    "    insd = collections.defaultdict(lambda: copy.deepcopy(ins))\n",
    "    trigrams = collections.defaultdict(lambda: copy.deepcopy(insd))\n",
    "    \n",
    "    num_lines = 179473348\n",
    "    lines_read = 0\n",
    "    mv = 0\n",
    "    with open(\"poleval_3grams.txt\", \"r\") as f:\n",
    "        with tqdm(total=num_lines) as pbar:\n",
    "            line = f.readline()\n",
    "            while line:\n",
    "                if lines_read > 10000:\n",
    "                    pbar.update(lines_read)\n",
    "                    lines_read = 0\n",
    "                    pbar.set_description(f\"memory used {sys.getsizeof(trigrams)/1024/1024} MB\")\n",
    "\n",
    "                lines_read += 1\n",
    "                try:\n",
    "                    wc, w1, w2, w3 = line.replace(\"\\n\", \"\").split(\" \")\n",
    "                    if int(wc) > 1:\n",
    "                        trigrams[w1][w2][w3] += int(wc)\n",
    "                        mv = max(mv, trigrams[w1][w2][w3])\n",
    "                except Exception:\n",
    "                    pass\n",
    "                line = f.readline()\n",
    " \n",
    "    return (trigrams, mv)\n",
    "            \n",
    "trigrams, max_c = succ_3grams()\n",
    "print(f\"normalize by {max_c}\")\n",
    "for w1 in trigrams.keys():\n",
    "    for w2 in trigrams[w1].keys():\n",
    "        for w3 in trigrams[w1][w2].keys():\n",
    "            trigrams[w1][w2][w3] = float(trigrams[w1][w2][w3])/float(max_c)\n",
    "trigrams['dupa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_sufix_3gram(suflen):\n",
    "    ins = collections.defaultdict(lambda: 0)\n",
    "    insd = collections.defaultdict(lambda: copy.deepcopy(ins))\n",
    "    sufgrams = collections.defaultdict(lambda: copy.deepcopy(insd))\n",
    "    procd = 0\n",
    "    pbar = tqdm(total=len(trigrams.keys()))\n",
    "    \n",
    "    for w1 in trigrams.keys():\n",
    "        procd += 1\n",
    "\n",
    "        if procd > 1000:\n",
    "            procd = 0\n",
    "            pbar.update(1000)\n",
    "            pbar.set_description(f\"memory used {str(sys.getsizeof(sufgrams)/1024/1024)[:5]} MB\")\n",
    "\n",
    "        if len(w1) > suflen:\n",
    "            pref_sufix = str(w1)[-suflen:]\n",
    "            for w2 in trigrams[w1].keys():\n",
    "                if len(str(w2)) > suflen:\n",
    "                    suf_sufix = str(w2)[-suflen:]\n",
    "                    for w3 in trigrams[w1][w2].keys():\n",
    "                        if len(str(w3)) > suflen:\n",
    "                            suf_suf_sufix = str(w3)[-suflen:]\n",
    "                            sufgrams[pref_sufix][suf_sufix][suf_suf_sufix] += trigrams[w1][w2][w3]\n",
    "                    \n",
    "    # normalize ...\n",
    "    biggest = 0\n",
    "    for w1 in sufgrams.keys():\n",
    "        for w2 in sufgrams[w1].keys():\n",
    "            for w3 in sufgrams[w1][w2].keys():\n",
    "                biggest = max(biggest, sufgrams[w1][w2][w3])\n",
    "    print(f\"maximum score was {biggest}\")\n",
    "    for w1 in sufgrams.keys():\n",
    "        for w2 in sufgrams[w1].keys():\n",
    "            for w3 in sufgrams[w1][w2].keys():\n",
    "                sufgrams[w1][w2][w3] = float(sufgrams[w1][w2][w3])/float(biggest)\n",
    "    \n",
    "    pbar.close()\n",
    "    return sufgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "009fbc67689c4a3abaf52a2aba8cb89d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=763569.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 1.1575646042039072\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16f0e21529a744e3838cd9ba34d7d8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=763569.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 0.2358399366188816\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71da8f9771074db69d59d741ca95e266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=763569.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 0.0691183974248839\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661ca8956fc24a91bda6404106efa1db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=763569.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 0.03963807742404309\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6208bc70ce18417194a929adaf60adf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=763569.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum score was 0.03703961184354644\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trigram_suflist = [calculate_sufix_3gram(i) for i in range(1, 6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(results, desired):\n",
    "    for resit, res in enumerate(results):\n",
    "        if desired == \" \".join(res[1:-1]):\n",
    "            return 1.0/(resit + 1.0)\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0030959752321981426"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_for_bigram(wa, wb):\n",
    "    return bigrams[wa][wb]\n",
    "\n",
    "def check_for_bisuf(wa, wb):\n",
    "    for it in range(5, 1, -1):\n",
    "        best = 0\n",
    "        if len(wa) > it and len(wb) > it:\n",
    "            sufa = wa[-it:]\n",
    "            sufb = wb[-it:]\n",
    "            if bigram_suflist[it-1][sufa][sufb] > 0.0:\n",
    "                return (bigram_suflist[it-1][sufa][sufb], it)\n",
    "\n",
    "def check_for_trigram(wa, wb, wc):\n",
    "    if trigrams[wa][wb][wc] > 0:\n",
    "        return trigrams[wa][wb][wc]\n",
    "    return 0\n",
    "\n",
    "def check_for_trisuf(wa, wb, wc):\n",
    "    for it in range(5, 1, -1):\n",
    "        best = 0\n",
    "        if len(wa) > it and len(wb) > it:\n",
    "            sufa = wa[-it:]\n",
    "            sufb = wb[-it:]\n",
    "            sufc = wc[-it:]\n",
    "            if trigram_suflist[it-1][sufa][sufb][sufc] > 0.0:\n",
    "                return (trigram_suflist[it-1][sufa][sufb][sufc], it)\n",
    "\n",
    "\n",
    "def permutation_analizer(sentence, normalization = None):\n",
    "    results = []\n",
    "    norm_vals = [0.0, 0.0, 0.0]\n",
    "    for pp in itertools.permutations(sentence):\n",
    "        p = [\"<BOS>\"] + list(pp) + [\"<EOS>\"]\n",
    "        score = 1.0\n",
    "        taintcount = []\n",
    "        for pit in range(len(p) - 1):\n",
    "            # check for full trigram\n",
    "            chunkscore = 0.0\n",
    "            if pit < len(p) - 2:\n",
    "                a1 = check_for_trigram(p[pit], p[pit+1], p[pit+2])\n",
    "            # check for full bigram\n",
    "            if pit < (len(p) - 1):\n",
    "                a2 = check_for_bigram(p[pit], p[pit+1])\n",
    "            \n",
    "            # check for prefsizes.\n",
    "            if pit < len(p) - 1:\n",
    "                discore = check_for_bisuf(p[pit], p[pit+1])\n",
    "            else:\n",
    "                discore = None\n",
    "\n",
    "            if pit < len(p) - 2:\n",
    "                triscore = check_for_trisuf(p[pit], p[pit+1], p[pit+2])\n",
    "            else:\n",
    "                triscore = None\n",
    "\n",
    "            if discore == None and triscore == None:\n",
    "                a3 = 0.0\n",
    "            elif discore == None and triscore is not None:\n",
    "                a3 = triscore[0]\n",
    "            elif discore is not None and triscore == None:\n",
    "                a3 = discore[0]\n",
    "            else:\n",
    "                if discore[1] > triscore[1]:\n",
    "                    a3 = discore[0]\n",
    "                else:\n",
    "                    a3 = triscore[1]\n",
    "                \n",
    "            if a1 + a2 + a3 == 0.0:\n",
    "                taintcount.append(p[pit])\n",
    "                chunkscore = 1e-100\n",
    "            else: \n",
    "                if normalization is None:\n",
    "                    chunkscore = a1+a2+a3\n",
    "                else:\n",
    "                    chunkscore = a1*normalization[0] + a2*normalization[1] + a3*normalization[2]\n",
    "                    \n",
    "            score *= chunkscore\n",
    "            norm_vals = [\n",
    "                max(norm_vals[vit], vi) for vit, vi in enumerate([a1, a2, a3])\n",
    "            ]\n",
    "        \n",
    "        results.append((-score, p, taintcount))\n",
    "    \n",
    "    if normalization is not None:\n",
    "        res = sorted(results)\n",
    "        return res\n",
    "        for r in res[:10]:\n",
    "            print(r)\n",
    "    else:\n",
    "        print(\"that was the normalization pass, please rerun with this argument\")\n",
    "\n",
    "    return norm_vals\n",
    "    \n",
    "pres = permutation_analizer(\"wczoraj wieczorem spotkałem pewną piękną kobietę\".split(\" \"), \n",
    "                     [1.0,\n",
    "                      0.001,\n",
    "                      0.000001,\n",
    "                     ])\n",
    "\n",
    "calculate_score(\n",
    "    [i[1] for i in pres],\n",
    "    \"wczoraj wieczorem spotkałem pewną piękną kobietę\")\n",
    "#permutation_analizer([\"judyta\", \"dała\", \"wczoraj\", \"stefanowi\", \"czekoladki\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "rundict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "509f16eaa8dc40678bfdc630760ebd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dry run for [1000000000.0, 100000000000.0, 1.0]\n",
      "dry run for [1000000000.0, 10000000000000.0, 1.0]\n",
      "dry run for [100000000000.0, 1000000000.0, 1.0]\n",
      "dry run for [100000000000.0, 100000000000.0, 1.0]\n",
      "dry run for [100000000000.0, 1000000000000.0, 1.0]\n",
      "dry run for [100000000000.0, 10000000000000.0, 1.0]\n",
      "dry run for [100000000000.0, 1000000000000000.0, 1.0]\n",
      "dry run for [1000000000000.0, 100000000000.0, 1.0]\n",
      "dry run for [1000000000000.0, 10000000000000.0, 1.0]\n",
      "dry run for [10000000000000.0, 1000000000.0, 1.0]\n",
      "dry run for [10000000000000.0, 100000000000.0, 1.0]\n",
      "dry run for [10000000000000.0, 1000000000000.0, 1.0]\n",
      "dry run for [10000000000000.0, 10000000000000.0, 1.0]\n",
      "dry run for [10000000000000.0, 1000000000000000.0, 1.0]\n",
      "dry run for [1000000000000000.0, 100000000000.0, 1.0]\n",
      "dry run for [1000000000000000.0, 10000000000000.0, 1.0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_test_suite(norm = [1.0, 0.0, 0.0]):\n",
    "    with open(\"test.txt\", \"r\") as f:\n",
    "        results = []\n",
    "        for t in f.read().split(\"\\n\"):\n",
    "            test = t.split(\" \")\n",
    "            response = permutation_analizer(test, norm)\n",
    "            results.append(calculate_score([r[1] for r in response], t))\n",
    "    return (statistics.mean(results), statistics.stdev(results))\n",
    "\n",
    "norms = []\n",
    "# 1000000.0, 1000000000.0\n",
    "for i in [1000000000.0,100000000000.0, 1000000000000.0, 10000000000000.0, 1000000000000000.0]:\n",
    "    for j in [1000000000.0,100000000000.0, 1000000000000.0, 10000000000000.0, 1000000000000000.0]:\n",
    "        for k in [1.0]:\n",
    "            norms.append([i, j, k])\n",
    "\n",
    "blessed = []\n",
    "for norm in tqdm(norms):\n",
    "    if f\"{norm[0]},{norm[1]},{norm[2]}\" in rundict:\n",
    "        blessed.append((rundict[f\"{norm[0]},{norm[1]},{norm[2]}\"], norm))\n",
    "    else:\n",
    "        print(f\"dry run for {norm}\")\n",
    "        run = run_test_suite(norm)\n",
    "        rundict[f\"{norm[0]},{norm[1]},{norm[2]}\"] = run\n",
    "        blessed.append((run, norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0.28979054852981806, 0.37192165717677056),\n",
       "  [100000000000.0, 1000000000000.0, 1.0]),\n",
       " ((0.29278514683329354, 0.35893466101620186),\n",
       "  [1000000000.0, 1000000000.0, 1.0]),\n",
       " ((0.29507451196643275, 0.35394991544017557),\n",
       "  [1000000000000000.0, 100000000000.0, 1.0]),\n",
       " ((0.30439954407513237, 0.36364063543562714),\n",
       "  [1000000000000.0, 1000000000.0, 1.0]),\n",
       " ((0.30780482954995037, 0.36285218329853186),\n",
       "  [10000000000000.0, 1000000000.0, 1.0])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sorted(blessed)[-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
