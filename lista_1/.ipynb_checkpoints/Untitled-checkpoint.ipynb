{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LISTA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GLOBAL SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "import collections\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZADANIE 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJP already downloaded, unpacking\n",
      "read 3045880 words from SJP, longest one is 15 letters long!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(\"sjp-20201007.zip\"):\n",
    "    print(\"doing a succ on SJP dictionary\")\n",
    "    os.system(\"wget https://sjp.pl/slownik/growy/sjp-20201007.zip\")\n",
    "else:\n",
    "    print(\"SJP already downloaded, unpacking\")\n",
    "\n",
    "if not os.path.isfile(\"slowa.txt\"):\n",
    "    os.system(\"unzip sjp-20201007.zip\")\n",
    "\n",
    "words = []\n",
    "with open(\"slowa.txt\", \"r\") as f:\n",
    "    words = set(f.read().split(\"\\n\"))\n",
    "    \n",
    "# the dict is mentally challenged and does not have 'i' in it\n",
    "words.add(\"i\")\n",
    "words.add(\"z\")\n",
    "\n",
    "\n",
    "longest = max(len(w) for w in words)    \n",
    "\n",
    "print(f\"read {len(words)} words from SJP, longest one is {longest} letters long!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kamienie', 'testowanie']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MaxMatch(w, verbose = False):\n",
    "    tokenized = []\n",
    "    succ = 1\n",
    "    best = (0, \"reeee\")\n",
    "    \n",
    "    while len(w) > 0:\n",
    "        try_ = w[:succ]\n",
    "        if try_ in words:\n",
    "            if verbose:\n",
    "                print(f\"found candidate {try_}\")\n",
    "            best = (succ, try_) \n",
    "\n",
    "        succ += 1\n",
    "        \n",
    "        if succ > longest or try_ == w:\n",
    "            if best[0] == 0:\n",
    "                raise Exception(f\"could not match {w[:succ]}\")\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print(f\"longest match was {best[1]}\")\n",
    "                tokenized.append(best[1])\n",
    "                if verbose:\n",
    "                    print(f\"transforming {w} -> {w[best[0]:]}\")\n",
    "                w = w[best[0]:]\n",
    "                succ = 1\n",
    "                best = (0, \"reeee\")\n",
    "    return tokenized\n",
    "                \n",
    "MaxMatch(\"kamienietestowanie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZADANIE 2 i 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3889/3889 [00:00<00:00, 18309.14it/s]\n",
      "  1%|          | 418/39566 [00:00<00:09, 4169.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got 39566 snippets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39566/39566 [00:11<00:00, 3583.79it/s]\n",
      "100%|██████████| 662051/662051 [00:00<00:00, 2255949.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calculate_bigrams():\n",
    "    text = []\n",
    "    for dir in tqdm(os.listdir(\"corpora/\")):\n",
    "        with open(f\"corpora/{dir}/text.xml\", \"r\") as corpfile:\n",
    "            corpseg = corpfile.read().split(\"\\n\")\n",
    "            for l in corpseg:\n",
    "                if \"<ab\" in l:\n",
    "                    l = l.replace(\"</ab>\", \"\")\n",
    "                    l = l.split(\">\")[1]\n",
    "                    text.append(l.lower())\n",
    "    print(f\"got {len(text)} snippets\")\n",
    "    \n",
    "    bigram_stat = collections.defaultdict(lambda: 0)\n",
    "    for sentence in tqdm(text):\n",
    "        tokens = nltk.word_tokenize(sentence)\n",
    "        for k in range(len(tokens) - 1):\n",
    "            key = f\"{tokens[k]}#{tokens[k+1]}\"\n",
    "            bigram_stat[key] += 1\n",
    "            \n",
    "    baked_bigrams = [(bigram_stat[k], k) for k in bigram_stat.keys()]\n",
    "    baked_bigrams = sorted(baked_bigrams, reverse=True)\n",
    "    return baked_bigrams\n",
    "    \n",
    "bigrams = calculate_bigrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 662051/662051 [00:01<00:00, 415527.07it/s]\n"
     ]
    }
   ],
   "source": [
    "bigram_dict = collections.defaultdict(lambda: [])\n",
    "for bfreq, bigram in tqdm(bigrams):\n",
    "    if bigram.count(\"#\") > 1:\n",
    "        continue\n",
    "    primary, secondary = bigram.split(\"#\")\n",
    "    bigram_dict[primary].append((bfreq, secondary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(max_len, starting, distribution):\n",
    "    if max_len == 0:\n",
    "        max_len = 1000000\n",
    "    if starting == None:\n",
    "        starting = random.choice(list(bigram_dict.keys()))\n",
    "        \n",
    "    while(max_len > 0):\n",
    "        print(starting, end = ' ')\n",
    "        max_len -= 1\n",
    "        candidates = bigram_dict[starting]\n",
    "        \n",
    "        if distribution == \"random\":\n",
    "            candidates = [c[1] for c in candidates]\n",
    "            if len(candidates) == 0:\n",
    "                return\n",
    "            starting = random.choice(candidates) \n",
    "            \n",
    "        if distribution == \"weight\":\n",
    "            if len(candidates) == 0:\n",
    "                return\n",
    "            all_ents = sum(c[0] for c in candidates)\n",
    "            chosen = random.randint(0, all_ents)\n",
    "            for it in range(len(candidates)):\n",
    "                chosen -= candidates[it][0]\n",
    "                if chosen <= 0:\n",
    "                    starting = candidates[it][1]\n",
    "                    break\n",
    "                    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "papież cierpi z zastrzeżeniem ust . kierunki , gdzie z polską walutę wymienialną ( ironia ... a prawko to niezły \n",
      "=======\n",
      "papież zostałby w nocy , można było żyć bez pracy , ale to nie mogliśmy podać niemało trzy godziny wieczorne \n",
      "=======\n",
      "papież nawiązał do takiego czy na polskim '' . im pod mantyneją . dla moich kapłanów w nowym domu wiesława \n",
      "=======\n",
      "papież się w formie komunikatu wydanego w okolicy było zgodnie z tym , mających zastosowanie przepisy prawne rozróżnienie wydaje ten \n",
      "=======\n",
      "papież benedykt xvi wieku , z powodu pewnej chwili do suwałk . wszystko jedno zdanie z otwartymi oczami . nie \n",
      "=======\n",
      "papież jan sibiga , po 1 . cóż dopiero przed redakcją na kempingu samochodowego secz we wściekłość holendra spotęgowały rzęsiste \n",
      "=======\n",
      "papież , dawniej tłumacz i realizować . nie chcąc nie posiadała znaczne zbliżenie . drzwi , jeden plus procent to \n",
      "=======\n",
      "papież zwołał też lubił kobiety są jednak wycieku testów przydatności w rękę , helu . nie chce nie przeszkadzała w \n",
      "=======\n",
      "papież nawiązał kontakt z dyrektywami przerwały po zestawieniu notowań . a ja tylko odejdą smutki , parsknęła śmiechem , marzą \n",
      "=======\n",
      "papież uciekł z wysiłku , którym niedawno oglądaliśmy ich stoliku dwaj - w ubiegłych w jordell bank pbi s.a. w \n",
      "=======\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    generate_story(20, \"papież\", \"weight\")\n",
    "    print(\"\\n=======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
